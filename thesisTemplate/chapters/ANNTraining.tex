% !TEX encoding = UTF-8
% !TEX TS-program = pdflatex
% !TEX root = ../Tesi.tex
% !TEX spellcheck = en-EN

%************************************************
\chapter{Artificial Neural Network Generalization}
\label{cap:anntraining}
%************************************************

\section{Principal Component Analysis (PCA) Results}
\label{sec:pcaanalysis}

We evaluated the linear relationship between the microscopic and the
macroscopic parameters in the training simulations with Matlab Principal
Component Analysis.
The results can be seen in Table \ref{tab:06inputRelationshipTable}.
Sliding friction (\acs{mus}), rolling friction (\acs{mur}) and particle density (\acs{rhop})
had the greatest influence on, respectively, the coefficient of pre-shear
(\acs{mupsh}), the angle of repose  (\acs{AoR}) and the bulk density (\acs{rhob}). Notably, \acs{rhop}
was not used as a training parameter for \acs{AoR} bulk behaviour. \\
However, we can see how each relationship is below the 100\% necessary to claim
a direct linear correlation.
Thus, we demonstrated that we need more precise statistical tools to investigate
the relationships and generalize the results.

\input{tables/06inputRelationshipTable}

\section{Regression statistic training concept}
\label{sec:regressiontrainingconcept}

\input{images/127anntraining}

Initially, as shown in Fig. \ref{fig:019methodology} in the training phase
(dashed lines) \acs{DEM} simulations are performed
with random initial input parameters.
The behaviours obtained are used to train the following regression models:
\begin{itemize}
  \item{Bayesian linear,}
  \item{Gaussian non linear,}
  \item{Artificial Neural Network (\acs{ANN}).}
\end{itemize}
For all the three models training consists in a loop that continues until the
difference between the outputs of each model and its samples is below the
limit ($\Delta$) (see Chapter \ref{cap:ann} for more details).\\
Thus, we were able to use the \acs{DEM} parameter combinations and their
corresponding bulk values to train the models.
Especially, we divided the samples in three pools: the first, with 70\% of the
samples, as \textit{training set}, the second, with 15\% of the samples, as
\textit{generalization set}, for early stopping, and the third, as \textit{test
set}, as suggested by Haykin (2009). The assignment of each sample to each pool
was random.

\subsection{ANN training concept specifications}
\label{subsec:anntrainingconceptspecifications}

The training of an \acs{ANN} consists in defining the weights and the biases for
each of its neuron.
We first defined the typology of Artificial Neural Networks (\acs{ANNs}) we used and
the input we fed them, see Benvenuti et al. \cite{RefWorks:205}.
Our \acs{ANNs} have three different layers: the input layer has a number of neurons
equal to the number of different inputs of the network, see Fig.
\ref{fig:018nnscheme}, with the scheme of how the Multilayer Perceptron \acs{ANN} ($MLPNN$) derives one
bulk-behaviour-dependent variable from the mutually independent simulation variables.
The hidden (or central) layer's number of neurons was to be investigated. 
The output layer contains one neuron for the output.
The transfer function for the neurons of the central layer is the tangential
sigmoid, while the neuron of the output layer use the linear transfer
function.\\
\input{images/018nnscheme}
We started with all the \acs{DEM} parameter combinations and their corresponding
numerical \acs{mupsh} from the \textit{training set} to create 36 \acs{ANNs} that
differed in their numbers of neurons in the hidden layer (between five to forty neurons).
The \textit{generalization set} was used to speed the training. 
We then determined the coefficient of determination (\acs{r2}), 
\input{equations/rSquare}
between the
$bulk-macro$ behaviours in the output of the \acs{ANN} and the \textit{test
set} simulations, which were not correlated with the remaining 70\% used for the
training.
Thus, we could select for \acs{mupsh} the \acs{ANN} with the maximum \acs{r2}, 
again as suggested by Vaferi et al. \cite{RefWorks:150}, and we noted its number
of neurons.
We repeated the same \acs{ANN} creation steps for \acs{mush}, \acs{rhob}
and \acs{AoR}, obtaining one trained \acs{ANN} for each bulk value. \\

\subsection{Sinter fine ANN training}
\label{subsec:sinterfineanntraining}

As said, we started with the sinter fine.
The first bulk value \acs{ANN} trained was the \acs{mupsh}, where we achieved a
$\acs{r2} = 0.96$ for an \acs{ANN} with fifteen neurons, a consistent agreement between the 
\acs{DEM} and the \acs{ANN} values, which demonstrates the accurate predictive power of
the \acs{ANN}, compared to the other two methods.
Increasing the number of neurons did not improve the \acs{r2}; it even started to
oscillate with higher numbers of neurons.
We subsequently obtained the optimal number of neurons for all \acs{ANNs}.\\
Later, we obtained Fig.
\ref{fig:022regression}, where the corresponding plot for the \acs{ANN} with the maximum \acs{r2} is shown. 
Each circle represents one of the 546 simulations.
\input{images/022regression}

\section{Statistical tools comparison}
\label{sec:statisticaltoolscomparison}

%\input{images/077regressions}
\input{images/143sctregressions}
\input{images/144aorregressions}

We checked \acs{r2}, \textit{mean absolute error}, 
\input{equations/meanAbsoluteError}
\textit{mean squared error},
\input{equations/meanSquareError}
and \textit{root mean squared error},
\input{equations/rootMeanSquareError}
for the \textit{Bayesian linear
regression}, the \textit{Gaussian nonlinear
regression}, and the
\textit{\acs{ANN} regression} to establish the most effective method.
All were trained with the same training set. 
For instance, a comparison of the \acs{r2} for the \acs{mupsh} can be see in 
Fig. \ref{fig:143sctregressions}.
In Fig. \ref{fig:144aorregressions} a similar comparison for the \acs{AoR} can
be found.\\
In fact, the check was performed for each method by comparing the
\acs{DEM} bulk values of the test set against the bulk values predicted by each method from the 
corresponding \acs{DEM} input values of the test set. \\
Table \ref{tab:15regressionvalues} shows a quantitative comparison between the
three methods for the \acs{mupsh}. 
\input{tables/15regressionvalues}
%************************************************

\section{Parameter Identification}
\label{sec:parameteridentification}

Since \acs{mupsh}, \acs{mush} and \acs{rhob} belonged to the shear-cell
simulations, their \acs{ANNs} were handled together: we had one cluster with three 
\acs{ANNs} for the shear cell and one with only one \acs{ANN} for the \acs{AoR}.
We could then proceed in identifying valid input parameters.

\subsection{Computational Condiderations}
\label{subsec:computationalcondiderations}

\citet{RefWorks:116, RefWorks:160} suggested using a Design of Experiments
(\acs{DoE}) method to determine the parameter combinations to be simulated.
They stated that this approach allows optimization of computation time
with an acceptable loss of precision.
The speed of the trained \acs{ANNs} enabled us to follow a different approach to
maximizing the precision of the characterization.\\

\input{tables/12DEMRandominputvalues}

\subsection{Decisional Limits}
\label{subsec:decisionallimits}

We created random values
in the range and numbers defined in Table \ref{tab:12DEMRandominputvalues}
according to a standard uniform distribution.
The total number of combinations of these random values was 6,250,000.
These combinations were then fed to and processed by the selected
\acs{ANNs}, and thus three bulk values for the shear
cell and one for the \acs{AoR} were obtained.
The \acs{ANN} evaluation was significantly faster than the \acs{DEM} simulations. The
individuation of the numerical bulk behaviours for all the \acs{DEM} combinations
did not take more than a few seconds on a single core.\\
\input{images/019methodology}
As can be seen in Fig. \ref{fig:019methodology}, in the parameters
identification phase (solid lines) we identify valid input parameters by comparing (\textbf{=}) \acs{ANNs} and
experimental behaviours.\\
We obtained for each of the twelve load conditions of the \acs{SCT} three bulk
values (\acs{mupsh}, \acs{mush} and \acs{rhob}).
The fourth bulk value was the result of two angle of repose (\acs{AoR}) tests that
recreated the repose angle observed in a pile of the
real material. 
Subsequently, we compared the \acs{ANN} and experimental bulk behaviours for the
twelve shear-cell load conditions.
If in a DEM-parameter combination all the three bulk values differed by less 
than 5\% from those of the corresponding experiments, i.e.:
%************************************************
\input{equations/check2}
the combination was marked. The marked combinations were processed by the
\acs{AoR} \acs{ANN}, and then compared with the experiment.
Were considered valid those that differed by less than $5\%$ also in this
comparison (Eq. \ref{eq:checkaor}):
%************************************************
\input{equations/checkaor}

\subsection{Reliability Considerations}
\label{subsec:reliabilityconsiderations}

We tested the marked combinations
by modifying the experimental bulk values of the shear cell to further prove
the validity of the system.
We artificially decreased or increased the shear force, and thus \acs{mupsh} and
\acs{mush}, by a product coefficient ($P$), e.g. Eq. \ref{eq:pcoeff}:
%************************************************
\input{equations/pcoeff}

\subsection{Value representation}
\label{subsec:valuerepresentation}

\begin{itemize}
  \item{parameter space plot;}
  \item{box plot;}
  \item{density plot.}
\end{itemize}

\subsubsection{Parameter space plot}
\label{subsubsec:parameterspaceplot}

An example of a parameter space plot can be seen
in Fig. \ref{fig:041radarpirker1schulze1068}.
On the axes we can see:
\begin{itemize}
  \item{the \acl{CoR} (\acs{CoR}),}
  \item{the \acl{mus} (\acs{mus}),}
  \item{the \acl{mur} (\acs{mur}),}  
  \item{the \acl{rhob} (\acs{rhob}).}
\end{itemize}
Further, are shown:
\begin{itemize}
  \item{the minimum input values amongst the millions possible combinations,
  with a blue straight line;}
  \item{the minimum values amongst the valid, or marked combinations, with a
  green straight line;}
  \item{the mean values amongst the valid, or marked combinations, with an
  orange dotted line;}
  \item{the negative standard deviations from the mean values amongst the valid,
  or marked combinations, with a red straight line;}
  \item{the positive standard deviations from the mean values amongst the valid,
  or marked combinations, with a red straight line;}  
  \item{the maximum values amongst the valid, or marked combinations, with a
  green straight line;}
  \item{the maximum input values amongst the millions possible combinations,
  with a blue straight line.}  
\end{itemize}

The shaded area indicates valid parameter combinations, and dark shaded
values indicate the confidence range

\input{images/149paramspaceplotsct1068}


\subsubsection{Box plot}
\label{subsubsec:boxplot}
  
An example of a box plot can be seen
in Fig. \ref{fig:145BoxSCT1068p08sinterfine}.
\citet{RefWorks:207} defines a box plot a graphical representation of
collections of numerical data by means of their quartiles.
These are three points, which divide the data in four groups that are equals and
contain a quarter of the data each.\\
In a box plot the values between the first quartile (25\%) and the third
quartile (75\%) are included in a blue box.
Further, so called \textit{baffles} or \textit{whishers} are lines, which are
extended as far as the minimum and maximum values.
Finally, the median is represented as a red straight line.

\input{images/146boxplotsct1068}

\subsubsection{Density plot}
\label{subsubsec:densityplot}

Further, we observed that various \acs{DEM} parameter
combinations could reproduce the experimental behaviour, and thus evaluated
their mutual dependencies.
This is shown more clearly in a density plot (e.g., Fig. 
\ref{fig:150ParamSpaceSCT1068p08sinterfine}) 
of the particles' coefficient of restitution (\acs{CoR}) in relation to
the coefficients of sliding friction (\acs{mus}) and rolling friction (\acs{mur}); 
in the white area, no valid sets of simulation parameters could be found.
In each cell the valid sets are grouped according to the 4 different COR
ranges.
Each cell is coloured according to the group with the most members.

\input{images/155tileplotsct1068sinterfine}

%************************************************
%************************************************

\subsection{SCT parameter space plot for Sinter fine}
\label{subsec:sctparameterspacesinterfine}

\input{images/079sctparameterspaceplots}

The comparison between numerical and experimental behaviours led to a first
series of marked combinations ($MC1$) for two load conditions of
the shear cell:
\begin{itemize}
  \item{$\acs{sigman} = 1,068$ Pa, P=1.0, as plotted in Fig.
  \ref{fig:041radarpirker1schulze1068},}
  \item{$\acs{sigman} = 10,070$ Pa, P=1.0, as plotted in Fig.
  \ref{fig:024radarpirker1schulze10070}.}
\end{itemize}
Note that the confidence interval is large, 
especially for the \acs{CoR}, which highlights its insignificant influence on the
characterization.
Both the \acs{rhop}  and the \acs{mus}, however, show a narrow confidence interval, 
which demonstrates their influence and the ability of this procedure to find
valid \acs{DEM} parameters.
These results agree with our examination of the ratio of the standard deviation
to the range, see Table \ref{tab:13DEMvalidvalues}.

\subsection{SCT box plot for Sinter fine}
\label{subsec:sctboxsinterfine}

\input{images/156boxplotsct10070sinterfine}

\subsection{SCT cloud space}
\label{subsec:sctcloudspace}

Multiple
combinations (250,407 or 4\% of the total) of \acs{mus} and \acs{mur} reproduced
the experimental behaviour with varying \acs{CoR}.
This underlines once more their correlation, as already stated by Wensrich and 
Katterfeld \cite{RefWorks:87}.

\input{images/080sctdensityplots}

\subsection{Product coeffiecient effect}
\label{subsec:productcoeffiecienteffect}

To further demonstrate the validity of the procedure, we modified the product
coefficient. 
First, we set it to $P=0.8$, and we obtained another
series of marked combinations ($MC2$).
It could be seen in the parameter space plot in Fig.
\ref{fig:026radarpirker08schulze10070} that the confidence range is narrower
than for $P=1.0$, while in the density plot in Fig. 
\ref{fig:159TileSCT10070p08sinterfine} the area
appears larger, although slightly less densely populated. Finally, for $P=1.2$
and its marked combinations ($MC3$) the parameter space plot in Fig.
\ref{fig:028radarpirker12schulze10070} shows a largely different confidence
range, while the density plot in Fig. \ref{fig:161TileSCT10070p12sinterfine} 
shows a smaller area. As expected, the procedure was highly sensitive to
variations in the experimental data.
Our approach could therefore be used
for a wide range of bulk materials.\\

\subsection{AoR and merge results}
\label{subsec:aorandmergeresults}

We then processed the random combinations with the \acs{AoR} \acs{ANN}. In Fig.
\ref{fig:031radarpirker1aor} the parameter space plot for the same criteria as
before could be seen.
In accordance with theory (Wensrich and Katterfeld \cite{RefWorks:87}), in a simulation dominated
by rolling particles, the coefficient of rolling friction has the maximum
influence. \\
Finally, we extracted from the $MC1$ values the \acs{AoR} \acs{ANN} behaviour
and compared it with the experimental one.
As could be seen in the parameter space plot in Fig.
\ref{fig:033radarpirker1schulze10070aor}, the confidence interval is very small,
indicating that all the parameters but the \acs{CoR} played an important role, 
and demonstrating the reliability of these parameter
combinations in representing the bulk behaviour.
From the initial 6,250,000 combinations, only 3,884 were valid (0.0621
\%), see Table \ref{tab:13DEMvalidvalues}.
%************************************************
% \input{tables/05sinterTableExperimental}
% \info{one table for each material? here or in the polydispersity chapter?}

\input{tables/13DEMvalidvalues}


%************************************************


%081aorandmergeparameterspaceplots}
\input{images/207aorparameterspaceplots}
\input{images/208mergeparameterspaceplots}


%************************************************
%************************************************

\section{Influence of poly-dispersity}
\label{sec:polydispersity}
%************************************************

% \info{Some examples of the new images: relationship between the standard
% deviation of the radius and the shape of the tile plot.}
% 
% \improvement{table similar to \ref{tab:12DEMRandominputvalues} here}
% \wrong{separate all images into single with captions}
% \change{add box plots?}
% 
% Fig. \ref{fig:082ironore0315}\\
% \input{images/082ironore0315}
% 
% Fig. \ref{fig:083ironore31510}\\
% \input{images/083ironore31510}
% 
% Fig. \ref{fig:084limestone0315}\\
% \input{images/084limestone0315}
% 
% Fig. \ref{fig:085limestone31510}\\
% \input{images/085limestone31510}
% 
% Fig. \ref{fig:086sinter0315}\\
% \input{images/086sinter0315}
% 
% Fig. \ref{fig:087sinter31510}\\
% \input{images/087sinter31510}


\input{tables/25DEMvalidvaluescokecoarse}
\input{tables/26DEMvalidvaluescokefine}
\input{tables/27DEMvalidvaluesironorecoarse}
\input{tables/28DEMvalidvaluesironorefine}
\input{tables/29DEMvalidvalueslimestonecoarse}
\input{tables/30DEMvalidvalueslimestonefine}
\input{tables/31DEMvalidvaluessintercoarse}


\input{tables/32weightsbiasesAOR}
\input{tables/33weightsbiasesmuie}


\input{images/209boxplotscokecoarse}
\input{images/210tileplotscokecoarse}

\input{images/211boxplotscokefine}
\input{images/212tileplotscokefine}
\input{images/213boxplotsironorecoarse}
\input{images/214tileplotsironorecoarse}
\input{images/215boxplotsironorefine}
\input{images/216tileplotsironorefine}
\input{images/217boxplotslimestonecoarse}
\input{images/218tileplotslimestonecoarse}

\input{images/219boxplotslimestonefine}
\input{images/220tileplotslimestonefine}

\input{images/221boxplotssintercoarse}
\input{images/222tileplotssintercoarse}

\section{Discussion of Model Limitations}
\label{sec:discussion}
%************************************************
In our approach we established a relationship between particle scale contact law
parameters and macroscopic bulk behaviour by means of $ANN$. 
In case the chosen contact law is physically correct by its functional dependencies, 
this micro to macro relationship can be used in a reversed way to identify 
valid sets of contact law parameters.\\
However, in case the chosen contact law is not applicable to the granular 
material under consideration, 
our procedure might lead to a wrong set of parameters, which might lead to the
correct bulk behaviour.
In this case a first error (incorrect contact law) might be annulled by another
one (wrong parameters).\\
To avoid such misleading results, the functional dependency of the particle based contact 
law should be chosen with care, taking into account the contact physics in the granular 
flow regime under investigation. 
Further, our $ANN$ based parameter
identification should be applied to different macroscopic bulk behaviours. 
If those parameter identifications do not 
lead to a common set of valid parameters, most probably the chosen contact law was not applicable. 